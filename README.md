# Financial Fraud Detection

A comprehensive machine learning project for detecting financial fraud using classification algorithms. Implements complete preprocessing and model training pipelines with OOP-based modules following industry best practices.

## Project Structure

```
financial-fraud-detection/
â”œâ”€â”€ data/                  # Data directory (see data/README.md)
â”‚   â”œâ”€â”€ raw/                # Original, immutable source datasets
â”‚   â””â”€â”€ processed/          # Cleaned and transformed datasets
â”œâ”€â”€ src/                    # Production source code modules
â”‚   â”œâ”€â”€ data_loader.py           # Data loading & validation
â”‚   â”œâ”€â”€ data_cleaner.py          # Data cleaning
â”‚   â”œâ”€â”€ geolocation.py           # IP to country mapping
â”‚   â”œâ”€â”€ feature_engineer.py      # Feature engineering
â”‚   â”œâ”€â”€ eda.py                   # Exploratory data analysis
â”‚   â”œâ”€â”€ data_transformer.py      # Scaling & encoding
â”‚   â”œâ”€â”€ imbalance_handler.py     # SMOTE/undersampling
â”‚   â”œâ”€â”€ preprocessor.py          # Preprocessing pipeline
â”‚   â”œâ”€â”€ data_preparator.py       # Train-test split
â”‚   â”œâ”€â”€ model_trainer.py         # Model training
â”‚   â”œâ”€â”€ model_evaluator.py       # Model evaluation
â”‚   â”œâ”€â”€ cross_validator.py       # Cross-validation
â”‚   â”œâ”€â”€ hyperparameter_tuner.py  # Hyperparameter tuning
â”‚   â””â”€â”€ model_pipeline.py        # Complete model pipeline
â”œâ”€â”€ notebooks/              # Interactive Jupyter notebooks
â”‚   â”œâ”€â”€ eda-fraud-data.ipynb
â”‚   â”œâ”€â”€ eda-creditcard.ipynb
â”‚   â”œâ”€â”€ feature-engineering.ipynb
â”‚   â”œâ”€â”€ modeling.ipynb           # Task 2: Model building
â”‚   â””â”€â”€ shap-explainability.ipynb
â”œâ”€â”€ models/                 # Model artifacts (see models/README.md)
â”‚   â”œâ”€â”€ *.joblib            # Saved trained models
â”‚   â””â”€â”€ evaluation_outputs/ # Evaluation visualizations
â”œâ”€â”€ reports/                 # Project reports (see reports/README.md)
â”‚   â””â”€â”€ INTERIM_REPORT_TASK1.md
â”œâ”€â”€ tests/                   # Test suite (see tests/README.md)
â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â””â”€â”€ integration/        # Integration tests
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â””â”€â”€ generate_visualizations.py
â””â”€â”€ requirements.txt         # Python dependencies
```

## Directory Usage

### `data/` - Data Management

**Purpose**: Store all datasets used in the project.

- **`data/raw/`**: Original, immutable source datasets. Never modify files here.
  - Place source CSV files: `Fraud_Data.csv`, `creditcard.csv`, `IpAddress_to_Country.csv`
- **`data/processed/`**: Cleaned and transformed datasets generated by preprocessing pipeline.
  - Contains: processed CSVs, EDA visualizations, saved transformers

**See**: `data/README.md` for detailed guidelines.

### `src/` - Source Code

**Purpose**: Production-ready Python modules implementing core functionality.

- Modular OOP design with single responsibility principle
- Comprehensive error handling and logging
- Reusable classes for data processing and model training
- All modules can be imported and used independently

### `notebooks/` - Interactive Analysis

**Purpose**: Jupyter notebooks for exploratory analysis and demonstrations.

- Use for interactive data exploration
- Document analysis workflows
- Share findings and visualizations
- Not for production code (use `src/` instead)

### `models/` - Model Artifacts

**Purpose**: Store trained models and evaluation outputs.

- **Saved Models**: Serialized model files (`.joblib` format)
- **Configurations**: Model hyperparameters and settings
- **Evaluations**: Confusion matrices, PR curves, ROC curves, comparison tables

**See**: `models/README.md` for usage details.

### `reports/` - Documentation

**Purpose**: Project reports and documentation.

- Interim and final reports
- Methodology documentation
- Business recommendations
- Technical specifications

**See**: `reports/README.md` for contents.

### `tests/` - Test Suite

**Purpose**: Unit and integration tests for code quality assurance.

- **`tests/unit/`**: Test individual modules and functions in isolation
- **`tests/integration/`**: Test complete pipelines and workflows

**See**: `tests/README.md` for testing guidelines.

### `scripts/` - Utility Scripts

**Purpose**: Standalone utility scripts for automation.

- Data generation scripts
- Visualization generation
- Batch processing utilities

## Quick Start

### 1. Setup

```bash
# Clone repository
git clone <repository-url>
cd financial-fraud-detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Data

Place your datasets in `data/raw/`:
- `Fraud_Data.csv` - E-commerce fraud data
- `creditcard.csv` - Credit card fraud data
- `IpAddress_to_Country.csv` - IP to country mapping (optional)

### 3. Run Preprocessing (Task 1)

```python
from src.preprocessor import PreprocessingPipeline

pipeline = PreprocessingPipeline()
processed_df, metadata = pipeline.process_fraud_data(
    fraud_data_file="Fraud_Data.csv",
    perform_eda=True,
    handle_imbalance=True
)
```

### 4. Train Models (Task 2)

```python
from src.model_pipeline import ModelPipeline

model_pipeline = ModelPipeline()
results = model_pipeline.build_and_evaluate_models(
    df=processed_df,
    target_column="class",
    perform_cv=True,
    ensemble_model="random_forest"
)
```

## Testing

### Run All Tests

```bash
# From project root
pytest tests/ -v
```

### Run Unit Tests Only

```bash
pytest tests/unit/ -v
```

### Run Integration Tests Only

```bash
pytest tests/integration/ -v
```

### Run with Coverage Report

```bash
# Generate coverage report
pytest tests/ --cov=src --cov-report=html --cov-report=term

# View HTML report
open htmlcov/index.html  # Mac/Linux
# or
start htmlcov/index.html  # Windows
```

### End-to-End Testing

To test the complete pipeline end-to-end:

```bash
# 1. Run unit tests
pytest tests/unit/ -v

# 2. Run integration tests (requires data files)
pytest tests/integration/ -v

# 3. Check coverage
pytest tests/ --cov=src --cov-report=term-missing

# 4. Run with verbose output
pytest tests/ -v --tb=short
```

**Note**: Integration tests may require data files in `data/raw/`. See individual test files for requirements.

## Features

### Task 1: Data Preprocessing
- âœ… Data loading with validation
- âœ… Missing value imputation & duplicate removal
- âœ… IP to country geolocation mapping
- âœ… Feature engineering (temporal, velocity, frequency)
- âœ… Data transformation (scaling, encoding)
- âœ… Class imbalance handling (SMOTE, undersampling)
- âœ… Comprehensive EDA with visualizations

### Task 2: Model Building & Training
- âœ… Stratified train-test split (preserves class distribution)
- âœ… Baseline model: Logistic Regression with class weights
- âœ… Ensemble models: Random Forest, XGBoost, LightGBM
- âœ… Model evaluation: AUC-PR, F1-Score, ROC-AUC, Confusion Matrix
- âœ… Cross-validation: Stratified K-Fold (k=5)
- âœ… Hyperparameter tuning with RandomizedSearchCV
- âœ… Model comparison and selection
- âœ… Model persistence (save/load)

## Datasets

### Credit Card Fraud Detection
- **Source:** [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) | [Zenodo](https://zenodo.org/record/7395559)
- **Size:** 284,807 transactions (492 fraudulent, 0.17%)
- **Features:** Time, V1-V28 (PCA), Amount, Class

### Fraud Data (E-commerce)
- **Expected columns:** user_id, signup_time, purchase_time, purchase_value, ip_address, class
- **Note:** Custom dataset structure

### IP to Country Mapping
- **Sources:** MaxMind GeoIP2, IP2Location, DB-IP
- **Format:** lower_bound_ip_address, upper_bound_ip_address, country

## Usage Examples

### Complete Pipeline

```python
# 1. Preprocess data
from src.preprocessor import PreprocessingPipeline
preprocessor = PreprocessingPipeline()
df, _ = preprocessor.process_fraud_data("Fraud_Data.csv")

# 2. Train and evaluate models
from src.model_pipeline import ModelPipeline
modeler = ModelPipeline()
results = modeler.build_and_evaluate_models(df, target_column="class")

# 3. Access best model
best_model = results['best_model']['model']
```

### Individual Modules

```python
from src.data_preparator import DataPreparator
from src.model_trainer import ModelTrainer
from src.model_evaluator import ModelEvaluator

# Prepare data
prep = DataPreparator()
X_train, X_test, y_train, y_test = prep.prepare_data(df, "class")

# Train model
trainer = ModelTrainer()
model = trainer.train_random_forest(X_train, y_train)

# Evaluate
evaluator = ModelEvaluator()
metrics = evaluator.evaluate_model(model, X_test, y_test)
```

## Notebooks

- **`notebooks/modeling.ipynb`** - Complete model building pipeline (Task 2)
- **`notebooks/eda-fraud-data.ipynb`** - EDA for fraud data
- **`notebooks/feature-engineering.ipynb`** - Feature engineering examples

## Requirements

Key dependencies:
- pandas, numpy - Data manipulation
- scikit-learn - Machine learning
- xgboost, lightgbm - Ensemble models
- imbalanced-learn - Class imbalance handling
- matplotlib, seaborn - Visualization
- shap - Model explainability (Task 3)
- pytest, pytest-cov - Testing

See `requirements.txt` for complete list.

## Project Status

- âœ… **Task 1:** Data preprocessing pipeline complete
- âœ… **Task 2:** Model building and training complete
- ðŸ”„ **Task 3:** Model explainability (SHAP) - In progress

## Contributing

1. Create a feature branch
2. Write tests for new functionality
3. Ensure all tests pass: `pytest tests/ -v`
4. Submit a pull request

## License

TBD
