{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Preprocessing Pipeline\n",
        "\n",
        "This notebook demonstrates the complete preprocessing pipeline using the PreprocessingPipeline class.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path\n",
        "sys.path.append(str(Path.cwd().parent / \"src\"))\n",
        "\n",
        "from preprocessor import PreprocessingPipeline\n",
        "\n",
        "print(\"Preprocessing pipeline imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the complete preprocessing pipeline\n",
        "pipeline = PreprocessingPipeline(\n",
        "    data_dir=\"../data/raw\",\n",
        "    output_dir=\"../data/processed\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process Fraud Data\n",
        "\n",
        "This will execute the complete pipeline:\n",
        "1. Load data\n",
        "2. Clean data (handle missing values, remove duplicates, correct types)\n",
        "3. Integrate geolocation (IP to country mapping)\n",
        "4. Engineer features (time-based, transaction frequency, velocity)\n",
        "5. Perform EDA\n",
        "6. Transform data (scaling and encoding)\n",
        "7. Handle class imbalance (SMOTE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process fraud data through complete pipeline\n",
        "try:\n",
        "    processed_df, metadata = pipeline.process_fraud_data(\n",
        "        fraud_data_file=\"Fraud_Data.csv\",\n",
        "        ip_country_file=\"IpAddress_to_Country.csv\",  # Optional\n",
        "        target_column=\"class\",\n",
        "        user_column=\"user_id\",\n",
        "        purchase_datetime=\"purchase_time\",\n",
        "        signup_datetime=\"signup_time\",\n",
        "        ip_column=\"ip_address\",\n",
        "        perform_eda=True,\n",
        "        handle_imbalance=True,\n",
        "        save_processed=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nFinal processed data shape: {processed_df.shape}\")\n",
        "    print(f\"\\nSteps completed: {metadata['steps_completed']}\")\n",
        "    \n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Data file not found: {e}\")\n",
        "    print(\"Please ensure the data files are in the data/raw directory\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in preprocessing: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## View Processed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display processed data info\n",
        "if 'processed_df' in locals():\n",
        "    print(\"Processed Data Info:\")\n",
        "    print(f\"Shape: {processed_df.shape}\")\n",
        "    print(f\"\\nColumns ({len(processed_df.columns)}):\")\n",
        "    print(list(processed_df.columns))\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(processed_df.head())\n",
        "    print(f\"\\nData types:\")\n",
        "    print(processed_df.dtypes)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
