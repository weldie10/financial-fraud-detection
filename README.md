# Financial Fraud Detection

A comprehensive machine learning project for detecting financial fraud using classification algorithms. Implements complete preprocessing and model training pipelines with OOP-based modules following industry best practices.

## Project Structure

```
financial-fraud-detection/
â”œâ”€â”€ data/                  # Data directory (see data/README.md)
â”‚   â”œâ”€â”€ raw/                # Original, immutable source datasets
â”‚   â””â”€â”€ processed/          # Cleaned and transformed datasets
â”œâ”€â”€ src/                    # Production source code modules
â”‚   â”œâ”€â”€ data_loader.py           # Data loading & validation
â”‚   â”œâ”€â”€ data_cleaner.py          # Data cleaning
â”‚   â”œâ”€â”€ geolocation.py           # IP to country mapping
â”‚   â”œâ”€â”€ feature_engineer.py      # Feature engineering
â”‚   â”œâ”€â”€ eda.py                   # Exploratory data analysis
â”‚   â”œâ”€â”€ data_transformer.py      # Scaling & encoding
â”‚   â”œâ”€â”€ imbalance_handler.py     # SMOTE/undersampling
â”‚   â”œâ”€â”€ preprocessor.py          # Preprocessing pipeline
â”‚   â”œâ”€â”€ data_preparator.py       # Train-test split
â”‚   â”œâ”€â”€ model_trainer.py         # Model training
â”‚   â”œâ”€â”€ model_evaluator.py       # Model evaluation
â”‚   â”œâ”€â”€ cross_validator.py       # Cross-validation
â”‚   â”œâ”€â”€ hyperparameter_tuner.py  # Hyperparameter tuning
â”‚   â”œâ”€â”€ model_pipeline.py        # Complete model pipeline
â”‚   â”œâ”€â”€ model_explainer.py       # SHAP explainability
â”‚   â”œâ”€â”€ business_recommender.py   # Business recommendations
â”‚   â”œâ”€â”€ explainability_pipeline.py # Complete explainability pipeline
â”‚   â””â”€â”€ explainability_service.py  # Production explainability service
â”œâ”€â”€ notebooks/              # Interactive Jupyter notebooks
â”‚   â”œâ”€â”€ eda-fraud-data.ipynb
â”‚   â”œâ”€â”€ eda-creditcard.ipynb
â”‚   â”œâ”€â”€ feature-engineering.ipynb
â”‚   â”œâ”€â”€ modeling.ipynb           # Task 2: Model building
â”‚   â””â”€â”€ shap-explainability.ipynb # Task 3: Model explainability
â”œâ”€â”€ models/                 # Model artifacts (see models/README.md)
â”‚   â”œâ”€â”€ *.joblib            # Saved trained models
â”‚   â””â”€â”€ evaluation_outputs/ # Evaluation visualizations
â”œâ”€â”€ dashboard/              # Interactive web dashboard (see dashboard/README.md)
â”‚   â”œâ”€â”€ app.py             # Streamlit dashboard application
â”‚   â””â”€â”€ README.md          # Dashboard documentation
â”œâ”€â”€ api/                    # Production API services (see api/README.md)
â”‚   â”œâ”€â”€ explainability_api.py  # REST API for SHAP explanations
â”‚   â””â”€â”€ README.md          # API documentation
â”œâ”€â”€ reports/                 # Project reports (see reports/README.md)
â”‚   â””â”€â”€ INTERIM_REPORT_TASK1.md
â”œâ”€â”€ tests/                   # Test suite (see tests/README.md)
â”‚   â”œâ”€â”€ unit/               # Unit tests
â”‚   â””â”€â”€ integration/        # Integration tests
â”œâ”€â”€ scripts/                 # Utility scripts
â”‚   â”œâ”€â”€ generate_visualizations.py
â”‚   â”œâ”€â”€ run_dashboard.sh   # Dashboard startup script
â”‚   â”œâ”€â”€ train_model.py     # Quick model training script
â”‚   â”œâ”€â”€ fix_dependencies.sh # Dependency compatibility fix
â”‚   â””â”€â”€ run_explainability_api.sh # API startup script
â””â”€â”€ requirements.txt         # Python dependencies
```

## Directory Usage

### `data/` - Data Management

**Purpose**: Store all datasets used in the project.

- **`data/raw/`**: Original, immutable source datasets. Never modify files here.
  - Place source CSV files: `Fraud_Data.csv`, `creditcard.csv`, `IpAddress_to_Country.csv`
- **`data/processed/`**: Cleaned and transformed datasets generated by preprocessing pipeline.
  - Contains: processed CSVs, EDA visualizations, saved transformers

**See**: `data/README.md` for detailed guidelines.

### `src/` - Source Code

**Purpose**: Production-ready Python modules implementing core functionality.

- Modular OOP design with single responsibility principle
- Comprehensive error handling and logging
- Reusable classes for data processing and model training
- All modules can be imported and used independently

### `notebooks/` - Interactive Analysis

**Purpose**: Jupyter notebooks for exploratory analysis and demonstrations.

- Use for interactive data exploration
- Document analysis workflows
- Share findings and visualizations
- Not for production code (use `src/` instead)

### `models/` - Model Artifacts

**Purpose**: Store trained models and evaluation outputs.

- **Saved Models**: Serialized model files (`.joblib` format)
- **Configurations**: Model hyperparameters and settings
- **Evaluations**: Confusion matrices, PR curves, ROC curves, comparison tables

**See**: `models/README.md` for usage details.

### `reports/` - Documentation

**Purpose**: Project reports and documentation.

- Interim and final reports
- Methodology documentation
- Business recommendations
- Technical specifications

**See**: `reports/README.md` for contents.

### `tests/` - Test Suite

**Purpose**: Unit and integration tests for code quality assurance.

- **`tests/unit/`**: Test individual modules and functions in isolation
- **`tests/integration/`**: Test complete pipelines and workflows

**See**: `tests/README.md` for testing guidelines.

### `dashboard/` - Interactive Dashboard

**Purpose**: Web-based interface for stakeholders to explore predictions and insights.

- **Streamlit Application**: Interactive dashboard for fraud analysis
- **Real-Time Predictions**: Make predictions for individual transactions
- **SHAP Explanations**: Understand fraud drivers visually
- **Scenario Testing**: Test different transaction scenarios

**See**: `dashboard/README.md` for detailed usage guide.

### `scripts/` - Utility Scripts

**Purpose**: Standalone utility scripts for automation.

- Data generation scripts
- Visualization generation
- Batch processing utilities
- Dashboard startup script

## Quick Start

### 1. Setup

```bash
# Clone repository
git clone <repository-url>
cd financial-fraud-detection

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Prepare Data

Place your datasets in `data/raw/`:
- `Fraud_Data.csv` - E-commerce fraud data
- `creditcard.csv` - Credit card fraud data
- `IpAddress_to_Country.csv` - IP to country mapping (optional)

### 3. Run Preprocessing (Task 1)

```python
from src.preprocessor import PreprocessingPipeline

pipeline = PreprocessingPipeline()
processed_df, metadata = pipeline.process_fraud_data(
    fraud_data_file="Fraud_Data.csv",
    perform_eda=True,
    handle_imbalance=True
)
```

### 4. Train Models (Task 2)

```python
from src.model_pipeline import ModelPipeline

model_pipeline = ModelPipeline()
results = model_pipeline.build_and_evaluate_models(
    df=processed_df,
    target_column="class",
    perform_cv=True,
    ensemble_model="random_forest"
)
```

### 5. Explain Model (Task 3)

```python
from src.explainability_pipeline import ExplainabilityPipeline

explainability = ExplainabilityPipeline()
results = explainability.explain_model(
    model=best_model,
    X_train=X_train,
    X_test=X_test,
    y_test=y_test,
    model_name="Random Forest"
)

# Access recommendations
for rec in results['recommendations']:
    print(f"{rec['title']}: {rec['recommendation']}")
```

## Testing

This project includes comprehensive unit and integration tests to ensure code correctness, reliability, and regulatory compliance for financial applications.

### Test Structure

- **Unit Tests** (`tests/unit/`): Test individual modules in isolation
  - Data processing: `DataLoader`, `DataCleaner`, `FeatureEngineer`, `ImbalanceHandler`, `DataTransformer`
  - Model training: `ModelTrainer`, `ModelEvaluator`, `CrossValidator`, `DataPreparator`
  - Geolocation: `GeolocationMapper`
  
- **Integration Tests** (`tests/integration/`): Test complete pipelines end-to-end
  - `PreprocessingPipeline`: Full data preprocessing workflow
  - `ModelPipeline`: Complete model training workflow

### Running Tests

#### Run All Tests

```bash
# From project root
pytest tests/ -v
```

#### Run Unit Tests Only

```bash
pytest tests/unit/ -v
```

#### Run Integration Tests Only

```bash
pytest tests/integration/ -v
```

#### Run Specific Test File

```bash
pytest tests/unit/test_data_loader.py -v
```

#### Run Specific Test Function

```bash
pytest tests/unit/test_data_loader.py::TestDataLoader::test_load_csv_success -v
```

### Coverage Reports

#### Generate Coverage Report

```bash
# Terminal report with missing lines
pytest tests/ --cov=src --cov-report=term-missing

# HTML report (generated in htmlcov/)
pytest tests/ --cov=src --cov-report=html

# View HTML report
open htmlcov/index.html  # Mac/Linux
# or
start htmlcov/index.html  # Windows
```

#### Coverage Requirements

- **Minimum Coverage**: 70% (configured in `pytest.ini`)
- **Current Status**: Tests cover all core functionality including:
  - Feature engineering (transaction frequency, velocity, time features)
  - SMOTE handling and class imbalance mitigation
  - Model scoring and evaluation metrics
  - Data preprocessing pipelines
  - Model training and persistence

### Key Test Scenarios

**Data Processing:**
- âœ… CSV loading with validation and error handling
- âœ… Missing value imputation (mean, median, mode, KNN)
- âœ… Duplicate removal and data type correction
- âœ… Feature engineering (time features, transaction frequency/velocity)
- âœ… SMOTE resampling and class distribution verification
- âœ… Data transformation (scaling, encoding)

**Model Training:**
- âœ… Stratified train-test split with class distribution preservation
- âœ… Baseline model training (Logistic Regression)
- âœ… Ensemble model training (Random Forest, XGBoost, LightGBM)
- âœ… Model evaluation metrics (PR-AUC, F1-Score, ROC-AUC)
- âœ… Cross-validation with stratified K-Fold
- âœ… Model persistence (save/load)

**Integration:**
- âœ… Complete preprocessing pipeline (fraud data and credit card data)
- âœ… End-to-end model training workflow
- âœ… Model comparison and selection

### Regulatory Compliance

For financial applications, comprehensive testing is critical:

- **Correctness**: All core functions verified (feature engineering, SMOTE handling, model scoring)
- **Reproducibility**: Fixed random seeds ensure consistent results
- **Documentation**: All tests documented for audit purposes
- **Coverage**: High test coverage demonstrates thoroughness

**See**: `tests/README.md` for detailed testing documentation.

## Features

### Task 1: Data Preprocessing
- âœ… Data loading with validation
- âœ… Missing value imputation & duplicate removal
- âœ… IP to country geolocation mapping
- âœ… Feature engineering (temporal, velocity, frequency)
- âœ… Data transformation (scaling, encoding)
- âœ… Class imbalance handling (SMOTE, undersampling)
- âœ… Comprehensive EDA with visualizations

### Task 2: Model Building & Training
- âœ… Stratified train-test split (preserves class distribution)
- âœ… Baseline model: Logistic Regression with class weights
- âœ… Ensemble models: Random Forest, XGBoost, LightGBM
- âœ… Model evaluation: AUC-PR, F1-Score, ROC-AUC, Confusion Matrix
- âœ… Cross-validation: Stratified K-Fold (k=5)
- âœ… Hyperparameter tuning with RandomizedSearchCV
- âœ… Model comparison and selection
- âœ… Model persistence (save/load)

### Task 3: Model Explainability
- âœ… Built-in feature importance extraction and visualization
- âœ… SHAP summary plot (global feature importance)
- âœ… SHAP force plots for individual predictions (TP, FP, FN)
- âœ… Feature importance comparison (built-in vs SHAP)
- âœ… Top 5 fraud prediction drivers identification
- âœ… Individual prediction analysis with detailed explanations
- âœ… Business recommendations generator with SHAP justification
- âœ… Automatic case finding (True Positive, False Positive, False Negative)
- âœ… **Production Explainability Service**: Reusable service for on-demand SHAP explanations
- âœ… **REST API**: Microservice API for real-time explainability
- âœ… **Dashboard Integration**: Real-time SHAP explanations in interactive dashboard

## Datasets

### Credit Card Fraud Detection
- **Source:** [Kaggle](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud) | [Zenodo](https://zenodo.org/record/7395559)
- **Size:** 284,807 transactions (492 fraudulent, 0.17%)
- **Features:** Time, V1-V28 (PCA), Amount, Class

### Fraud Data (E-commerce)
- **Expected columns:** user_id, signup_time, purchase_time, purchase_value, ip_address, class
- **Note:** Custom dataset structure

### IP to Country Mapping
- **Sources:** MaxMind GeoIP2, IP2Location, DB-IP
- **Format:** lower_bound_ip_address, upper_bound_ip_address, country

## Usage Examples

### Complete Pipeline

```python
# 1. Preprocess data
from src.preprocessor import PreprocessingPipeline
preprocessor = PreprocessingPipeline()
df, _ = preprocessor.process_fraud_data("Fraud_Data.csv")

# 2. Train and evaluate models
from src.model_pipeline import ModelPipeline
modeler = ModelPipeline()
results = modeler.build_and_evaluate_models(df, target_column="class")

# 3. Access best model
best_model = results['best_model']['model']

# 4. Explain model predictions
from src.explainability_pipeline import ExplainabilityPipeline
explainability = ExplainabilityPipeline()
explain_results = explainability.explain_model(
    model=best_model,
    X_train=X_train,
    X_test=X_test,
    y_test=y_test
)
```

### Individual Modules

```python
from src.data_preparator import DataPreparator
from src.model_trainer import ModelTrainer
from src.model_evaluator import ModelEvaluator

# Prepare data
prep = DataPreparator()
X_train, X_test, y_train, y_test = prep.prepare_data(df, "class")

# Train model
trainer = ModelTrainer()
model = trainer.train_random_forest(X_train, y_train)

# Evaluate
evaluator = ModelEvaluator()
metrics = evaluator.evaluate_model(model, X_test, y_test)
```

## Interactive Dashboard

A web-based dashboard for fraud analysts, product managers, and business stakeholders to explore predictions, test scenarios, and understand fraud drivers without writing code.

### Quick Start

**First Time Setup:**
```bash
# 1. Train a model (if you don't have one)
python scripts/train_model.py

# 2. Run the dashboard
streamlit run dashboard/app.py

# Or use the helper script
./scripts/run_dashboard.sh
```

The dashboard will open at `http://localhost:8501`

**Note**: If you see "No models found", you need to train a model first using `scripts/train_model.py` or the modeling notebook.

### Dashboard Features

- **ğŸ”® Real-Time Predictions**: Make fraud predictions for individual transactions or batch CSV files
- **ğŸ“ˆ Model Performance**: View model metrics, ROC/PR curves, and confusion matrices
- **ğŸ” Fraud Drivers**: Explore SHAP explanations to understand what drives fraud predictions
- **ğŸ§ª Scenario Testing**: Test different transaction scenarios and visualize prediction changes

**See**: `dashboard/README.md` for detailed documentation.

## Notebooks

- **`notebooks/modeling.ipynb`** - Complete model building pipeline (Task 2)
- **`notebooks/shap-explainability.ipynb`** - Model explainability with SHAP (Task 3)
- **`notebooks/eda-fraud-data.ipynb`** - EDA for fraud data
- **`notebooks/feature-engineering.ipynb`** - Feature engineering examples

## Requirements

Key dependencies:
- pandas, numpy - Data manipulation
- scikit-learn - Machine learning
- xgboost, lightgbm - Ensemble models
- imbalanced-learn - Class imbalance handling
- matplotlib, seaborn - Visualization
- shap - Model explainability (Task 3)
- pytest, pytest-cov - Testing

See `requirements.txt` for complete list.

## Project Status

- âœ… **Task 1:** Data preprocessing pipeline complete
- âœ… **Task 2:** Model building and training complete
- âœ… **Task 3:** Model explainability (SHAP) complete

## CI/CD Pipeline

This project includes a comprehensive CI/CD pipeline using GitHub Actions to ensure code quality, security, and reliability.

### Automated Quality Gates

The CI/CD pipeline runs automatically on:
- **Push** to `main`, `develop`, or `task-*` branches
- **Pull Requests** to `main` or `develop`
- **Manual trigger** via workflow_dispatch

### Pipeline Stages

#### 1. Code Linting (`lint` job)
- **Black**: Code formatting check
- **isort**: Import sorting verification
- **Flake8**: Code quality and style enforcement
- **Pylint**: Static code analysis

#### 2. Type Checking (`type-check` job)
- **MyPy**: Static type checking for Python code
- Validates type hints and catches type-related errors

#### 3. Testing (`test` job)
- **Unit Tests**: All unit tests run across Python 3.10, 3.11, 3.12
- **Integration Tests**: End-to-end pipeline tests
- **Coverage**: Minimum 70% code coverage required
- **Reports**: Coverage reports uploaded to Codecov and as artifacts

#### 4. Security Scanning (`security` job)
- **Safety**: Dependency vulnerability scanning
- **Bandit**: Security linter for common vulnerabilities

#### 5. Build Verification (`build` job)
- Verifies all critical imports work correctly
- Confirms code is ready for deployment

### Local Development

Run quality checks locally before pushing:

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Format code
black src/ tests/
isort src/ tests/

# Run linting
flake8 src/ tests/
pylint src/

# Type checking
mypy src/

# Security scanning
safety check --file requirements.txt
bandit -r src/

# Run tests with coverage
pytest tests/ --cov=src --cov-report=term-missing
```

### CI/CD Configuration Files

- **`.github/workflows/ci.yml`**: Main CI/CD pipeline
- **`.github/workflows/unittests.yml`**: Dedicated test workflow
- **`.flake8`**: Flake8 linting configuration
- **`.pylintrc`**: Pylint configuration
- **`pyproject.toml`**: Black, isort, mypy, pytest, coverage configuration

### Quality Metrics

- **Code Coverage**: Minimum 70% (enforced)
- **Python Versions**: 3.10, 3.11, 3.12 (tested)
- **Line Length**: 127 characters (configurable)
- **Complexity**: Maximum 10 (cyclomatic complexity)

### Status Badges

Add to your README to show CI/CD status:

```markdown
![CI/CD Pipeline](https://github.com/your-org/financial-fraud-detection/workflows/CI/CD%20Pipeline/badge.svg)
![Tests](https://github.com/your-org/financial-fraud-detection/workflows/Unit%20Tests/badge.svg)
![Coverage](https://codecov.io/gh/your-org/financial-fraud-detection/branch/main/graph/badge.svg)
```

## Contributing

1. Create a feature branch from `develop`
2. Write tests for new functionality
3. Ensure all quality checks pass locally:
   ```bash
   black src/ tests/
   flake8 src/ tests/
   pytest tests/ --cov=src
   ```
4. Push changes (CI/CD will run automatically)
5. Ensure all CI/CD checks pass
6. Submit a pull request

### Pre-commit Hooks (Optional)

Install pre-commit hooks for automatic checks:

```bash
pip install pre-commit
pre-commit install
```

This will run linting and formatting checks before each commit.

## License

TBD
